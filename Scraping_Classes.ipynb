{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Name': 'Integrity Energy ', 'ID': 'fed118be-f416-4929-b934-f260b927269e', 'Timestamp': 1668604936.953332, 'Href': 'https://www.trustpilot.com/review/integrityenergy.com', 'Number of Reviews': '134', 'Rating': '4.8', 'Email': '(216) 420-9700'}, {'Name': 'EZ Energy Services  ', 'ID': '4e313beb-de11-4dcf-8889-4376097e0ed8', 'Timestamp': 1668604944.945694, 'Href': 'https://www.trustpilot.com/review/ezenergyservices.com', 'Number of Reviews': '83', 'Rating': '4.8', 'Email': 'support@ezenergyservices.com'}]\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import re\n",
    "import uuid\n",
    "import json\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "class Scraper_Object:\n",
    "    def __init__(self, category, url):\n",
    "        self.category = category\n",
    "        self.url = url\n",
    "        self.crawler = []\n",
    "        self.scraped_data = []\n",
    "        driver.get(url)\n",
    "\n",
    "    def accept_cookies(self):\n",
    "        time.sleep(12)\n",
    "        accept_cookies_button = driver.find_element(By.XPATH, '//*[@id=\"onetrust-accept-btn-handler\"]')\n",
    "        accept_cookies_button.click()\n",
    "        time.sleep(1)\n",
    "\n",
    "    def search(self):\n",
    "        search_bar = driver.find_element(By.XPATH, '//input[@class=\"herosearch_searchInputField__Pp2MD\"]')\n",
    "        search_bar.send_keys(self.category)\n",
    "        time.sleep(3)\n",
    "        #The following line identifies the first suggested category by finding the following sibling of the 'categories' heading under the search box\n",
    "        first_category = driver.find_element(By.XPATH, '//h4[contains(text(),\"Categories\")]//following-sibling::a')\n",
    "        first_category.click()\n",
    "        time.sleep(3)\n",
    "    \n",
    "    def create_crawler(self, length):\n",
    "        self.length = length\n",
    "        #creates a list of the html elements corresponding to different companies \n",
    "        items_list = driver.find_elements(By.XPATH, '//div[@class=\"paper_paper__1PY90 paper_outline__lwsUX card_card__lQWDv card_noPadding__D8PcU styles_wrapper__2JOo2\"]/a')\n",
    "        #Iterates through the html elements and puts each href into the crawler\n",
    "        for index in range(0, self.length):\n",
    "            href = items_list[index].get_attribute('href')\n",
    "            self.crawler.append(href)\n",
    "        return self.crawler\n",
    "\n",
    "    def scrape_from_crawler(self):\n",
    "        for item in self.crawler:\n",
    "            self.scraped_data.append(scrape_stuff(item))\n",
    "\n",
    "    #Method for saving the scraped data as a json file\n",
    "    def save_json(self):\n",
    "        file_name = \"raw_data/{}.json\".format(self.category.replace(\" \", \"_\"))\n",
    "        with open(file_name, 'w') as json_file:\n",
    "            json.dump(self.scraped_data, json_file)\n",
    "\n",
    "#A function that scrapes all of the relevant data from a single href from the crawler, and puts it into a dictionary\n",
    "def scrape_stuff(url):\n",
    "    driver.get(url)\n",
    "    time.sleep(1)\n",
    "    item_dictionary = {}  \n",
    "\n",
    "    #Finds name of company\n",
    "    Name = driver.find_element(By.XPATH, '//span[@class=\"typography_display-s__qOjh6 typography_appearance-default__AAY17 title_displayName__TtDDM\"]/.').text\n",
    "    item_dictionary['Name'] = Name\n",
    "\n",
    "    #Gives the item a unique ID (uuid4)\n",
    "    item_dictionary['ID'] = str(uuid.uuid4())\n",
    "\n",
    "    #Gives the item a timestamp\n",
    "    item_dictionary['Timestamp'] = time.time()\n",
    "\n",
    "    #Adds the href to item_dictionary\n",
    "    item_dictionary['Href'] = url\n",
    "\n",
    "    #Finds the number of reviews\n",
    "    try:\n",
    "        Num_reviews = driver.find_element(By.XPATH, '//p[@class=\"typography_body-l__KUYFJ typography_appearance-default__AAY17\"]/.').text\n",
    "        Number_reviews = Num_reviews.split(' ')\n",
    "        item_dictionary[\"Number of Reviews\"] = Number_reviews[0]\n",
    "    except:\n",
    "        item_dictionary[\"Number of Reviews\"] = \"N/A\"\n",
    "\n",
    "    #Finds the rating \n",
    "    try:\n",
    "        Rating = driver.find_element(By.XPATH, '//span[@class=\"typography_heading-m__T_L_X typography_appearance-default__AAY17\"]').text\n",
    "        item_dictionary[\"Rating\"] = Rating\n",
    "    except:\n",
    "        item_dictionary[\"Rating\"] = \"N/A\"\n",
    "    #Finds the email of the company\n",
    "    try:\n",
    "        Email = driver.find_element(By.XPATH, '//a[@class=\"link_internal__7XN06 typography_body-m__xgxZ_ typography_appearance-action__9NNRY link_link__IZzHN link_underlined__OXYVM\"]').text\n",
    "        item_dictionary['Email']= Email\n",
    "    except:\n",
    "        item_dictionary['Email']= \"N/A\"\n",
    "\n",
    "    return item_dictionary\n",
    "\n",
    "    #\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tester = Scraper_Object('energy supplier', 'https://www.trustpilot.com/')\n",
    "    tester.accept_cookies()\n",
    "    tester.search()\n",
    "    tester.create_crawler(2)\n",
    "    tester.scrape_from_crawler()\n",
    "    print(tester.scraped_data)\n",
    "    tester.save_json()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bc6aee26d74ebf5fd9ff223917f46591e174bd4f8a931b714fad2afe26fc6eae"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
